package pers.hll.aigc4chat.model.ollama.response.body;

import com.google.gson.annotations.SerializedName;
import lombok.Data;

/**  
 * 模型详情
 * <pre>{@code
 * {
 *   "modelfile": "# Modelfile generated by \"ollama show\"\n# To build a new Modelfile based on this one, replace the FROM line with:\n# FROM llava:latest\n\nFROM /Users/matt/.ollama/models/blobs/sha256:200765e1283640ffbd013184bf496e261032fa75b99498a9613be4e94d63ad52\nTEMPLATE \"\"\"{{ .System }}\nUSER: {{ .Prompt }}\nASSSISTANT: \"\"\"\nPARAMETER num_ctx 4096\nPARAMETER stop \"\u003c/s\u003e\"\nPARAMETER stop \"USER:\"\nPARAMETER stop \"ASSSISTANT:\"",
 *   "parameters": "num_ctx                        4096\nstop                           \u003c/s\u003e\nstop                           USER:\nstop                           ASSSISTANT:",
 *   "template": "{{ .System }}\nUSER: {{ .Prompt }}\nASSSISTANT: ",
 *   "details": {
 *     "format": "gguf",
 *     "family": "llama",
 *     "families": ["llama", "clip"],
 *     "parameter_size": "7B",
 *     "quantization_level": "Q4_0"
 *   }
 * }
 * }
 *
 * </pre>
 *
 * @author hll
 * @since 2024/05/03
 */  
@Data
public class ShowRespBody {

    @SerializedName("modelfile")
    private String modelFile;

    private String parameters;

    private String template;

    private Details details;
}